% ============================================
% Topic 01: Linear Algebra / çº¿æ€§ä»£æ•°
% ============================================
\section{çº¿æ€§ä»£æ•° / Linear Algebra}

% --------------------------------------------
% 1. Matrix Basics
% --------------------------------------------
\begin{studybox}{çŸ©é˜µåŸºç¡€ (Matrix Basics)}

\textbf{æ¦‚å¿µ (CN)}: çŸ©é˜µçš„å®šä¹‰ã€è¿ç®—å’Œæ€§è´¨

\textbf{Term (EN)}: Matrix, Transpose, Inverse, Determinant

\tcblower

\textbf{åŸºæœ¬è¿ç®—}:
\begin{itemize}[leftmargin=*]
    \item \textbf{åŠ æ³•}: $\mathbf{C} = \mathbf{A} + \mathbf{B}$ (åŒå°ºå¯¸çŸ©é˜µå¯¹åº”å…ƒç´ ç›¸åŠ )
    \item \textbf{ä¹˜æ³•}: $(\mathbf{AB})_{ij} = \sum_k a_{ik} b_{kj}$ (è¡Œä¹˜åˆ—)
    \item \textbf{è½¬ç½®}: $(\mathbf{A}^T)_{ij} = a_{ji}$ (è¡Œåˆ—äº’æ¢)
\end{itemize}

\textbf{Key Insight}: Matrix multiplication is NOT commutative: $\mathbf{AB} \neq \mathbf{BA}$ in general.

\end{studybox}

\begin{formulabox}
\textbf{è¡Œåˆ—å¼ (2Ã—2)}:
\begin{equation}
    \det\begin{pmatrix} a & b \\ c & d \end{pmatrix} = ad - bc
\end{equation}

\textbf{è¡Œåˆ—å¼ (3Ã—3, å±•å¼€)}:
\begin{equation}
    \det(\mathbf{A}) = a_{11}C_{11} + a_{12}C_{12} + a_{13}C_{13}
\end{equation}
å…¶ä¸­ $C_{ij}$ æ˜¯ä»£æ•°ä½™å­å¼ã€‚

\textbf{é€†çŸ©é˜µ}:
\begin{equation}
    \mathbf{A}^{-1} = \frac{1}{\det(\mathbf{A})} \text{adj}(\mathbf{A})
\end{equation}

\textbf{é€†çŸ©é˜µå­˜åœ¨æ¡ä»¶}: $\det(\mathbf{A}) \neq 0$ï¼ˆéå¥‡å¼‚çŸ©é˜µï¼‰
\end{formulabox}

% --------------------------------------------
% 2. Systems of Linear Equations
% --------------------------------------------
\begin{studybox}{çº¿æ€§æ–¹ç¨‹ç»„ (Systems of Linear Equations)}

\textbf{æ¦‚å¿µ (CN)}: æ±‚è§£ $\mathbf{Ax} = \mathbf{b}$ çš„æ–¹æ³•

\textbf{Term (EN)}: Gaussian Elimination, Cramer's Rule, LU Decomposition

\tcblower

\textbf{çŸ©é˜µå½¢å¼}:
\begin{equation}
    \mathbf{Ax} = \mathbf{b} \quad \Rightarrow \quad \mathbf{x} = \mathbf{A}^{-1}\mathbf{b}
\end{equation}

\textbf{å…‹è±é»˜æ³•åˆ™} (Cramer's Rule):
\begin{equation}
    x_i = \frac{\det(\mathbf{A}_i)}{\det(\mathbf{A})}
\end{equation}
å…¶ä¸­ $\mathbf{A}_i$ æ˜¯å°† $\mathbf{A}$ çš„ç¬¬ $i$ åˆ—æ›¿æ¢ä¸º $\mathbf{b}$ã€‚

\textbf{Key Insight}: Gaussian elimination is more efficient than Cramer's rule for large systems.

\end{studybox}

\begin{formulabox}
\textbf{é«˜æ–¯æ¶ˆå…ƒç¤ºä¾‹}:

åŸæ–¹ç¨‹ç»„:
\begin{equation}
    \begin{cases}
        2x + y = 5 \\
        4x + 3y = 11
    \end{cases}
\end{equation}

å¢å¹¿çŸ©é˜µ:
\begin{equation}
    \left(\begin{array}{cc|c}
        2 & 1 & 5 \\
        4 & 3 & 11
    \end{array}\right) 
    \xrightarrow{R_2 - 2R_1}
    \left(\begin{array}{cc|c}
        2 & 1 & 5 \\
        0 & 1 & 1
    \end{array}\right)
\end{equation}

å›ä»£: $y = 1$, $x = 2$
\end{formulabox}

% --------------------------------------------
% 3. Eigenvalues and Eigenvectors
% --------------------------------------------
\begin{studybox}{ç‰¹å¾å€¼ä¸ç‰¹å¾å‘é‡ (Eigenvalues \& Eigenvectors)}

\textbf{æ¦‚å¿µ (CN)}: æ»¡è¶³ $\mathbf{Av} = \lambda\mathbf{v}$ çš„æ ‡é‡ $\lambda$ å’Œéé›¶å‘é‡ $\mathbf{v}$

\textbf{Term (EN)}: Eigenvalue, Eigenvector, Characteristic Polynomial

\tcblower

\textbf{å®šä¹‰}:
\begin{equation}
    \mathbf{Av} = \lambda\mathbf{v} \quad \Leftrightarrow \quad (\mathbf{A} - \lambda\mathbf{I})\mathbf{v} = \mathbf{0}
\end{equation}

\textbf{æ±‚è§£æ­¥éª¤}:
\begin{enumerate}
    \item æ±‚ç‰¹å¾å¤šé¡¹å¼: $\det(\mathbf{A} - \lambda\mathbf{I}) = 0$
    \item è§£å‡ºç‰¹å¾å€¼ $\lambda_1, \lambda_2, \ldots$
    \item å¯¹æ¯ä¸ª $\lambda_i$ï¼Œè§£ $(\mathbf{A} - \lambda_i\mathbf{I})\mathbf{v} = \mathbf{0}$ å¾—ç‰¹å¾å‘é‡
\end{enumerate}

\textbf{Key Insight}: Eigenvalues reveal fundamental properties of a matrix (stability, principal directions).

\end{studybox}

\begin{formulabox}
\textbf{2Ã—2 çŸ©é˜µç‰¹å¾å€¼}:

å¯¹äº $\mathbf{A} = \begin{pmatrix} a & b \\ c & d \end{pmatrix}$:

\textbf{ç‰¹å¾å¤šé¡¹å¼}:
\begin{equation}
    \lambda^2 - (a+d)\lambda + (ad-bc) = 0
\end{equation}

\textbf{ç®€åŒ–}:
\begin{equation}
    \lambda^2 - \text{tr}(\mathbf{A})\lambda + \det(\mathbf{A}) = 0
\end{equation}

\textbf{è§£}:
\begin{equation}
    \lambda = \frac{\text{tr}(\mathbf{A}) \pm \sqrt{\text{tr}(\mathbf{A})^2 - 4\det(\mathbf{A})}}{2}
\end{equation}
\end{formulabox}

\begin{thmbox}[ç‰¹å¾å€¼æ€§è´¨]
\begin{itemize}
    \item $\sum \lambda_i = \text{tr}(\mathbf{A})$ï¼ˆç‰¹å¾å€¼ä¹‹å’Œ = è¿¹ï¼‰
    \item $\prod \lambda_i = \det(\mathbf{A})$ï¼ˆç‰¹å¾å€¼ä¹‹ç§¯ = è¡Œåˆ—å¼ï¼‰
    \item å¯¹ç§°çŸ©é˜µçš„ç‰¹å¾å€¼éƒ½æ˜¯å®æ•°
    \item æ­£å®šçŸ©é˜µçš„ç‰¹å¾å€¼éƒ½ > 0
\end{itemize}
\end{thmbox}

% --------------------------------------------
% 4. Vector Spaces
% --------------------------------------------
\begin{studybox}{å‘é‡ç©ºé—´ (Vector Spaces)}

\textbf{æ¦‚å¿µ (CN)}: æ»¡è¶³å‘é‡åŠ æ³•å’Œæ ‡é‡ä¹˜æ³•å°é—­æ€§çš„é›†åˆ

\textbf{Term (EN)}: Basis, Dimension, Span, Linear Independence

\tcblower

\textbf{å…³é”®æ¦‚å¿µ}:
\begin{itemize}[leftmargin=*]
    \item \textbf{çº¿æ€§æ— å…³}: æ²¡æœ‰å‘é‡å¯ä»¥è¡¨ç¤ºä¸ºå…¶ä»–å‘é‡çš„çº¿æ€§ç»„åˆ
    \item \textbf{åŸº (Basis)}: çº¿æ€§æ— å…³ä¸”å¼ æˆæ•´ä¸ªç©ºé—´çš„å‘é‡ç»„
    \item \textbf{ç»´åº¦ (Dimension)}: åŸºä¸­å‘é‡çš„ä¸ªæ•°
    \item \textbf{ç§© (Rank)}: çŸ©é˜µåˆ—ç©ºé—´çš„ç»´åº¦
\end{itemize}

\textbf{Key Insight}: Rank tells you the "effective" number of independent equations/constraints.

\end{studybox}

\begin{formulabox}
\textbf{ç§©-é›¶åŒ–åº¦å®šç†}:
\begin{equation}
    \text{rank}(\mathbf{A}) + \text{nullity}(\mathbf{A}) = n
\end{equation}
å…¶ä¸­ $n$ æ˜¯åˆ—æ•°ã€‚

\textbf{é½æ¬¡æ–¹ç¨‹ç»„è§£çš„ç»“æ„}:
\begin{itemize}[leftmargin=*]
    \item $\text{rank}(\mathbf{A}) = n$: å”¯ä¸€è§£ ($\mathbf{x} = \mathbf{0}$)
    \item $\text{rank}(\mathbf{A}) < n$: æ— ç©·å¤šè§£ï¼ˆè§£ç©ºé—´ç»´åº¦ = $n - \text{rank}$ï¼‰
\end{itemize}
\end{formulabox}

% --------------------------------------------
% Thesis Connection
% --------------------------------------------
\begin{thesisbox}
\textbf{çº¿æ€§ä»£æ•°ä¸ä¼ æ„Ÿå™¨èåˆ}:

ä½ çš„è®ºæ–‡ä½¿ç”¨ \textbf{MPU-6050 (6è½´ä¼ æ„Ÿå™¨)} è¿›è¡Œè·Œå€’æ£€æµ‹ã€‚

\textbf{ä¼ æ„Ÿå™¨èåˆ (Kalman Filter) ç”¨åˆ°çš„çº¿æ€§ä»£æ•°}:
\begin{itemize}
    \item çŠ¶æ€å‘é‡: $\mathbf{x} = [\theta, \dot{\theta}, \omega_{bias}]^T$
    \item çŠ¶æ€è½¬ç§»çŸ©é˜µ: $\mathbf{A} = \begin{pmatrix} 1 & dt & 0 \\ 0 & 1 & -dt \\ 0 & 0 & 1 \end{pmatrix}$
    \item åæ–¹å·®çŸ©é˜µæ›´æ–°: $\mathbf{P} = \mathbf{APA}^T + \mathbf{Q}$
\end{itemize}

\textbf{Jan Koller é—®é¢˜}: "How do you combine Accelerometer and Gyroscope data?"

\textbf{ç­”æ¡ˆ}: ä½¿ç”¨å¡å°”æ›¼æ»¤æ³¢å™¨ã€‚åŠ é€Ÿåº¦è®¡æä¾›ç»å¯¹å§¿æ€ï¼ˆæœ‰å™ªå£°ï¼‰ï¼Œé™€èºä»ªæä¾›è§’é€Ÿåº¦ç§¯åˆ†ï¼ˆæœ‰æ¼‚ç§»ï¼‰ã€‚å¡å°”æ›¼æ»¤æ³¢é€šè¿‡æœ€å°åŒ–åæ–¹å·®ï¼Œèåˆä¸¤è€…å¾—åˆ°æœ€ä¼˜ä¼°è®¡ã€‚æ ¸å¿ƒæ˜¯çŸ©é˜µè¿ç®—ï¼ˆçŠ¶æ€é¢„æµ‹ã€åæ–¹å·®æ›´æ–°ã€å¡å°”æ›¼å¢ç›Šè®¡ç®—ï¼‰ã€‚
\end{thesisbox}

% --------------------------------------------
% Exam Strategy
% --------------------------------------------
\begin{warnbox}[ğŸ”´ è€ƒè¯•é™·é˜± / Exam Pitfalls]
\begin{enumerate}
    \item \textbf{é€†çŸ©é˜µä¸å­˜åœ¨}: $\det(\mathbf{A}) = 0$ æ—¶çŸ©é˜µå¥‡å¼‚ï¼Œæ— é€†ï¼
    \item \textbf{ç‰¹å¾å‘é‡æ–¹å‘}: ç‰¹å¾å‘é‡ä¹˜ä»¥ä»»æ„éé›¶å¸¸æ•°ä»æ˜¯ç‰¹å¾å‘é‡ã€‚
    \item \textbf{çŸ©é˜µä¹˜æ³•é¡ºåº}: $\mathbf{AB}$ çš„å°ºå¯¸æ˜¯ $(m \times p)$ å½“ $\mathbf{A}$ æ˜¯ $m \times n$ï¼Œ$\mathbf{B}$ æ˜¯ $n \times p$ã€‚
\end{enumerate}
\end{warnbox}
